{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using Theano backend.\n",
      "Using gpu device 3: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5103)\n",
      "/opt/anaconda/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "#Import function to get the covariate matrix that includes spike history from previous bins\n",
    "from preprocessing_funcs import get_spikes_with_history\n",
    "\n",
    "#Import decoder functions\n",
    "import Decoder_funcs\n",
    "from Decoder_funcs import get_vaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural data should be a matrix of size \"number of time bins\" x \"number of neurons\", where each entry is the firing rate of a given neuron in a given time bin**\n",
    "\n",
    "**The output you are decoding should be a matrix of size \"number of time bins\" x \"number of features you are decoding\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# folder='/Users/jig289/Dropbox/MATLAB/Projects/In_Progress/BMI/Processed_Data/'\n",
    "folder='/home/jglaser2/Data/DecData/'\n",
    "\n",
    "with open(folder+'test_data.pickle','rb') as f:\n",
    "    neural_data,vels_binned=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Covariates ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins_current=1 #Whether to use concurrent time bin of neural data\n",
    "bins_before=13 #How many bins of neural data prior to the output are used for decoding\n",
    "bins_after=0 #How many bins of neural data after (and including) the output are used for decoding\n",
    "bins_surrounding=bins_before+bins_before+bins_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to get the covariate matrix that includes spike history from previous bins\n",
    "X=get_spikes_with_history(neural_data,bins_before,bins_after,bins_current)\n",
    "\n",
    "#Put in \"flat\" format for XGB and linear\n",
    "X_flat=X.reshape(X.shape[0],(X.shape[1]*X.shape[2]))\n",
    "\n",
    "#Set decoding output\n",
    "y=vels_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# zscore = lambda x: (x - scipy.stats.nanmean(x)) / scipy.stats.nanstd(x)\n",
    "def zscore_nan(X,axis):\n",
    "    X_zscore=(X - np.nanmean(X,axis=axis)) / np.nanstd(X,axis=axis)\n",
    "    return X_zscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Normalize\n",
    "\n",
    "X=zscore_nan(X,axis=0)\n",
    "X_flat=zscore_nan(X_flat,axis=0)\n",
    "\n",
    "# y=stats.zscore(y,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training/testing/validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set what part of data should be part of the training/testing/validation sets\n",
    "training_range=[0, 0.7]\n",
    "testing_range=[0.7, 0.85]\n",
    "valid_range=[0.85,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_examples=X.shape[0]\n",
    "\n",
    "#Note that each range has a buffer of\"bins_before\" bins at the beginning, and \"bins_after\" bins at the end\n",
    "#This makes it so that the different sets don't include overlapping neural data\n",
    "training_set=np.arange(np.int(np.round(training_range[0]*num_examples))+bins_before,np.int(np.round(training_range[1]*num_examples))-bins_after)\n",
    "testing_set=np.arange(np.int(np.round(testing_range[0]*num_examples))+bins_before,np.int(np.round(testing_range[1]*num_examples))-bins_after)\n",
    "valid_set=np.arange(np.int(np.round(valid_range[0]*num_examples))+bins_before,np.int(np.round(valid_range[1]*num_examples))-bins_after)\n",
    "\n",
    "#Divide covariates\n",
    "X_train=X[training_set,:,:] #Subtract X.shape[1] so we don't have overlap in the train/test sets\n",
    "X_flat_train=X_flat[training_set,:]\n",
    "y_train=y[training_set,:]\n",
    "\n",
    "X_test=X[testing_set,:,:] #Subtract X.shape[1] so we don't have overlap in the train/test sets\n",
    "X_flat_test=X_flat[testing_set,:]\n",
    "y_test=y[testing_set,:]\n",
    "\n",
    "X_valid=X[valid_set,:,:] #Subtract X.shape[1] so we don't have overlap in the train/test sets\n",
    "X_flat_valid=X_flat[valid_set,:]\n",
    "y_valid=y[valid_set,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Decoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiener Filter (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "model_regr=Decoder_funcs.lin_reg_model(X_flat_train,y_train)\n",
    "y_valid_pred_lin=model_regr.predict(X_flat_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost (Extreme Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fit model\n",
    "model_xgb=Decoder_funcs.xgb_model(X_flat_train,y_train,max_depth=3,num_round=200)\n",
    "#Get predictions\n",
    "y_valid_pred_xgb=Decoder_funcs.xgb_predict(model_xgb,X_flat_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "model_rnn=Decoder_funcs.SimpleRNN_model(X_train,y_train,units=400,dropout=0.25,num_epochs=10)\n",
    "y_valid_pred_rnn=model_rnn.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU (Gated Recurrent Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "model_gru=Decoder_funcs.GRU_model(X_train,y_train,units=400,dropout=0,num_epochs=10)\n",
    "y_valid_pred_gru=model_gru.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM (Long Short Term Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "model_lstm=Decoder_funcs.LSTM_model(X_train,y_train,units=400,dropout=.25,num_epochs=10)\n",
    "y_valid_pred_lstm=model_lstm.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.75176754708627846, 0.75100935332779484]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vafs_lin=get_vaf(y_valid,y_valid_pred_lin)\n",
    "vafs_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.759985513205789, 0.75694730773341012]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vafs_xgb=get_vaf(y_valid,y_valid_pred_xgb)\n",
    "vafs_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.81989414021421436, 0.7690404096532123]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vafs_rnn=get_vaf(y_test,y_test_pred_rnn)\n",
    "vafs_rnn=get_vaf(y_valid,y_valid_pred_rnn)\n",
    "vafs_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vafs_gru=get_vaf(y_test,y_test_pred_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.87430652141381116, 0.8300965085769989]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vafs_lstm=get_vaf(y_valid,y_valid_pred_lstm)\n",
    "vafs_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#As an example, I plot the first 1000 values of the x velocity (column index 0), both true and predicted with the Wiener filter\n",
    "fig_x_lin=plt.figure()\n",
    "plt.plot(y_test[0:1000,0],'b')\n",
    "plt.plot(y_test_pred_lin[0:1000,0],'r')\n",
    "#Save figure\n",
    "# fig_x_lin.savefig('x_velocity_decoding.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wiener_casc(X_flat_train,y_train,X_flat_test,y_test,deg=3):\n",
    "    num_outputs=y_train.shape[1]\n",
    "    y_test_pred_ln=np.empty(y_test.shape)\n",
    "    for i in range(num_outputs):\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(X_flat_train, y_train[:,i]) #Train\n",
    "        y_train_pred_lin=regr.predict(X_flat_train)    \n",
    "        p=np.polyfit(y_train_pred_lin,y_train[:,i],deg)\n",
    "        y_train_pred_ln=np.polyval(p,y_train_pred_lin)\n",
    "        #Predictions on test set\n",
    "        y_test_pred_lin=regr.predict(X_flat_test)\n",
    "        y_test_pred_ln[:,i]=np.polyval(p,y_test_pred_lin)\n",
    "    return y_test_pred_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_valid_pred_wc=wiener_casc(X_flat_train,y_train,X_flat_valid,y_valid,deg=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7584608604036065, 0.76774970824995847]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vafs_wc=get_vaf(y_valid,y_valid_pred_wc)\n",
    "vafs_wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
