{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All decoders (except KF and ensemble) run on full datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define what folder you're saving to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_folder=''\n",
    "# save_folder='/home/jglaser/Files/Neural_Decoding/Results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define what folder you're loading the files from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_folder=''\n",
    "# load_folder='/home/jglaser/Data/DecData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define what dataset you are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset='s1'\n",
    "# dataset='m1'\n",
    "# dataset='hc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define which decoder to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_wf=1 #Wiener Filter\n",
    "run_wc=0 #Wiener Cascade\n",
    "run_svr=0 #Support vector regression\n",
    "run_xgb=0 #XGBoost\n",
    "run_dnn=0 #Feedforward (dense) neural network\n",
    "run_rnn=0 #Recurrent neural network\n",
    "run_gru=0 #Gated recurrent units\n",
    "run_lstm=0 #Long short term memory network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages\n",
    "\n",
    "We import standard packages and functions from the accompanying .py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 40.0% of memory, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "#Import standard packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "#Add the main folder to the path, so we have access to the files there.\n",
    "#Note that if your working directory is not the Paper_code folder, you may need to manually specify the path to the main folder. For example: sys.path.append('/home/jglaser/GitProj/Neural_Decoding')\n",
    "sys.path.append('..') \n",
    "\n",
    "#Import function to get the covariate matrix that includes spike history from previous bins\n",
    "from preprocessing_funcs import get_spikes_with_history\n",
    "\n",
    "#Import metrics\n",
    "from metrics import get_R2\n",
    "from metrics import get_rho\n",
    "\n",
    "#Import decoder functions\n",
    "from decoders import WienerCascadeDecoder\n",
    "from decoders import WienerFilterDecoder\n",
    "from decoders import DenseNNDecoder\n",
    "from decoders import SimpleRNNDecoder\n",
    "from decoders import GRUDecoder\n",
    "from decoders import LSTMDecoder\n",
    "from decoders import XGBoostDecoder\n",
    "from decoders import SVRDecoder\n",
    "\n",
    "#Import Bayesian Optimization package\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Turn off deprecation warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "The data that we load is in the format described below. We have another example script, \"Example_format_data\" that may be helpful towards putting the data in this format.\n",
    "\n",
    "Neural data should be a matrix of size \"number of time bins\" x \"number of neurons\", where each entry is the firing rate of a given neuron in a given time bin\n",
    "\n",
    "The output you are decoding should be a matrix of size \"number of time bins\" x \"number of features you are decoding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if dataset=='s1':\n",
    "    with open(load_folder+'example_data_s1.pickle','rb') as f:\n",
    "    #     neural_data,vels_binned=pickle.load(f,encoding='latin1')\n",
    "        neural_data,vels_binned=pickle.load(f)\n",
    "        \n",
    "if dataset=='m1':\n",
    "    with open(load_folder+'example_data_m1.pickle','rb') as f:\n",
    "    #     neural_data,vels_binned=pickle.load(f,encoding='latin1')\n",
    "        neural_data,vels_binned=pickle.load(f)\n",
    "        \n",
    "if dataset=='hc':\n",
    "    with open(load_folder+'example_data_hc.pickle','rb') as f:\n",
    "    #     neural_data,pos_binned=pickle.load(f,encoding='latin1')\n",
    "        neural_data,pos_binned=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A. User Inputs\n",
    "The user can define what time period to use spikes from (with respect to the output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if dataset=='s1':\n",
    "    bins_before=6 #How many bins of neural data prior to the output are used for decoding\n",
    "    bins_current=1 #Whether to use concurrent time bin of neural data\n",
    "    bins_after=6 #How many bins of neural data after (and including) the output are used for decoding\n",
    "    \n",
    "if dataset=='m1':\n",
    "    bins_before=13 #How many bins of neural data prior to the output are used for decoding\n",
    "    bins_current=1 #Whether to use concurrent time bin of neural data\n",
    "    bins_after=0 #How many bins of neural data after (and including) the output are used for decoding\n",
    "    \n",
    "if dataset=='hc':\n",
    "    bins_before=4 #How many bins of neural data prior to the output are used for decoding\n",
    "    bins_current=1 #Whether to use concurrent time bin of neural data\n",
    "    bins_after=5 #How many bins of neural data after (and including) the output are used for decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B. Format Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Input Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove neurons with too few spikes in HC dataset\n",
    "if dataset=='hc':\n",
    "    nd_sum=np.nansum(neural_data,axis=0)\n",
    "    rmv_nrn=np.where(nd_sum<100)\n",
    "    neural_data=np.delete(neural_data,rmv_nrn,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Format for recurrent neural networks (SimpleRNN, GRU, LSTM)\n",
    "# Function to get the covariate matrix that includes spike history from previous bins\n",
    "X=get_spikes_with_history(neural_data,bins_before,bins_after,bins_current)\n",
    "\n",
    "# Format for Wiener Filter, Wiener Cascade, SVR, XGBoost, and Dense Neural Network\n",
    "#Put in \"flat\" format, so each \"neuron / time\" is a single feature\n",
    "X_flat=X.reshape(X.shape[0],(X.shape[1]*X.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Output Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set decoding output\n",
    "if dataset=='s1' or dataset=='m1':\n",
    "    y=vels_binned\n",
    "if dataset=='hc':\n",
    "    y=pos_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In HC dataset, remove time bins with no output (y value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if dataset=='hc':\n",
    "    #Remove time bins with no output (y value)\n",
    "    rmv_time=np.where(np.isnan(y[:,0]) | np.isnan(y[:,1]))\n",
    "    X=np.delete(X,rmv_time,0)\n",
    "    X_flat=np.delete(X_flat,rmv_time,0)\n",
    "    y=np.delete(y,rmv_time,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** In HC dataset, there is a long period without movement starting at ~80%, so we only use the first 80% of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if dataset=='hc':\n",
    "    X=X[:int(.8*X.shape[0]),:,:]\n",
    "    X_flat=X_flat[:int(.8*X_flat.shape[0]),:]\n",
    "    y=y[:int(.8*y.shape[0]),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3C. Define training/testing/validation sets\n",
    "We have 10 cross-validation folds. In each fold, 10% of the data is a test set, 10% is a validation set, and 80% is the training set. So in the first fold, for example, 0-10% is validation, 10-20% is testing, and 20-100% is training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_range_all=[[0,.1],[.1,.2],[.2,.3],[.3,.4],[.4,.5],\n",
    "                 [.5,.6],[.6,.7],[.7,.8],[.8,.9],[.9,1]]\n",
    "testing_range_all=[[.1,.2],[.2,.3],[.3,.4],[.4,.5],[.5,.6],\n",
    "                 [.6,.7],[.7,.8],[.8,.9],[.9,1],[0,.1]]\n",
    "#Note that the training set is not aways contiguous. For example, in the second fold, the training set has 0-10% and 30-100%.\n",
    "#In that example, we enter of list of lists: [[0,.1],[.3,1]]\n",
    "training_range_all=[[[.2,1]],[[0,.1],[.3,1]],[[0,.2],[.4,1]],[[0,.3],[.5,1]],[[0,.4],[.6,1]],\n",
    "                   [[0,.5],[.7,1]],[[0,.6],[.8,1]],[[0,.7],[.9,1]],[[0,.8]],[[.1,.9]]]\n",
    "\n",
    "num_folds=len(valid_range_all) #Number of cross validation folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize lists of results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#R2 values\n",
    "mean_r2_wf=np.empty(num_folds)\n",
    "mean_r2_wc=np.empty(num_folds)\n",
    "mean_r2_xgb=np.empty(num_folds)\n",
    "mean_r2_svr=np.empty(num_folds)\n",
    "mean_r2_dnn=np.empty(num_folds)\n",
    "mean_r2_rnn=np.empty(num_folds)\n",
    "mean_r2_gru=np.empty(num_folds)\n",
    "mean_r2_lstm=np.empty(num_folds)\n",
    "\n",
    "#Actual data\n",
    "y_test_all=[]\n",
    "y_train_all=[]\n",
    "y_valid_all=[]\n",
    "\n",
    "#Test predictions\n",
    "y_pred_wf_all=[]\n",
    "y_pred_wc_all=[]\n",
    "y_pred_xgb_all=[]\n",
    "y_pred_dnn_all=[]\n",
    "y_pred_rnn_all=[]\n",
    "y_pred_gru_all=[]\n",
    "y_pred_lstm_all=[]\n",
    "y_pred_svr_all=[]\n",
    "\n",
    "#Training predictions\n",
    "y_train_pred_wf_all=[]\n",
    "y_train_pred_wc_all=[]\n",
    "y_train_pred_xgb_all=[]\n",
    "y_train_pred_dnn_all=[]\n",
    "y_train_pred_rnn_all=[]\n",
    "y_train_pred_gru_all=[]\n",
    "y_train_pred_lstm_all=[]\n",
    "y_train_pred_svr_all=[]\n",
    "\n",
    "#Validation predictions\n",
    "y_valid_pred_wf_all=[]\n",
    "y_valid_pred_wc_all=[]\n",
    "y_valid_pred_xgb_all=[]\n",
    "y_valid_pred_dnn_all=[]\n",
    "y_valid_pred_rnn_all=[]\n",
    "y_valid_pred_gru_all=[]\n",
    "y_valid_pred_lstm_all=[]\n",
    "y_valid_pred_svr_all=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the following section, we**\n",
    "1. Loop across folds\n",
    "2. Extract the training/validation/testing data\n",
    "3. Preprocess the data\n",
    "4. Run the individual decoders (whichever have been specified in user options). This includes the hyperparameter optimization\n",
    "5. Save the results\n",
    "\n",
    "Note that the Wiener Filter, Wiener Cascade, and XGBoost decoders are commented most fully. So look at those for the best understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('R2s_wf:', array([ 0.75507432,  0.74963294]))\n",
      "\n",
      "\n",
      "('R2s_wf:', array([ 0.7387892 ,  0.76205446]))\n",
      "\n",
      "\n",
      "('R2s_wf:', array([ 0.74555775,  0.75825578]))\n",
      "\n",
      "\n",
      "('R2s_wf:', array([ 0.77492927,  0.78659448]))\n",
      "\n",
      "\n",
      "('R2s_wf:', array([ 0.73793071,  0.73693024]))\n",
      "\n",
      "\n",
      "('R2s_wf:', array([ 0.74214418,  0.74480398]))\n",
      "\n",
      "\n",
      "('R2s_wf:', array([ 0.7046639 ,  0.73708232]))\n",
      "\n",
      "\n",
      "('R2s_wf:', array([ 0.75018119,  0.75405937]))\n",
      "\n",
      "\n",
      "('R2s_wf:', array([ 0.73322777,  0.72556696]))\n",
      "\n",
      "\n",
      "('R2s_wf:', array([ 0.74048384,  0.75922882]))\n",
      "\n",
      "\n",
      "('time_elapsed:', 38.735183000564575)\n"
     ]
    }
   ],
   "source": [
    "t1=time.time() #If I want to keep track of how much time has elapsed\n",
    "\n",
    "num_examples=X.shape[0] #number of examples (rows in the X matrix)\n",
    "\n",
    "\n",
    "for i in range(num_folds): #Loop through the folds\n",
    "\n",
    "    ######### SPLIT DATA INTO TRAINING/TESTING/VALIDATION #########\n",
    "    \n",
    "    #Note that all sets have a buffer of\"bins_before\" bins at the beginning, and \"bins_after\" bins at the end\n",
    "    #This makes it so that the different sets don't include overlapping neural data\n",
    "    \n",
    "    #Get testing set for this fold\n",
    "    testing_range=testing_range_all[i]\n",
    "    testing_set=np.arange(np.int(np.round(testing_range[0]*num_examples))+bins_before,np.int(np.round(testing_range[1]*num_examples))-bins_after)\n",
    "\n",
    "    #Get validation set for this fold\n",
    "    valid_range=valid_range_all[i]\n",
    "    valid_set=np.arange(np.int(np.round(valid_range[0]*num_examples))+bins_before,np.int(np.round(valid_range[1]*num_examples))-bins_after)\n",
    "\n",
    "    #Get training set for this fold. \n",
    "    #Note this needs to take into account a non-contiguous training set (see section 3C)\n",
    "    training_ranges=training_range_all[i]\n",
    "    for j in range(len(training_ranges)): #Go through different separated portions of the training set\n",
    "        training_range=training_ranges[j]\n",
    "        if j==0: #If it's the first portion of the training set, make it the training set\n",
    "            training_set=np.arange(np.int(np.round(training_range[0]*num_examples))+bins_before,np.int(np.round(training_range[1]*num_examples))-bins_after)\n",
    "        if j==1: #If it's the second portion of the training set, concatentate it to the first\n",
    "            training_set_temp=np.arange(np.int(np.round(training_range[0]*num_examples))+bins_before,np.int(np.round(training_range[1]*num_examples))-bins_after)\n",
    "            training_set=np.concatenate((training_set,training_set_temp),axis=0)\n",
    "                \n",
    "    #Get training data\n",
    "    X_train=X[training_set,:,:]\n",
    "    X_flat_train=X_flat[training_set,:]\n",
    "    y_train=y[training_set,:]\n",
    "    \n",
    "    #Get testing data\n",
    "    X_test=X[testing_set,:,:]\n",
    "    X_flat_test=X_flat[testing_set,:]\n",
    "    y_test=y[testing_set,:]\n",
    "\n",
    "    #Get validation data\n",
    "    X_valid=X[valid_set,:,:]\n",
    "    X_flat_valid=X_flat[valid_set,:]\n",
    "    y_valid=y[valid_set,:]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    ##### PREPROCESS DATA #####\n",
    "    \n",
    "    #Z-score \"X\" inputs. \n",
    "    X_train_mean=np.nanmean(X_train,axis=0) #Mean of training data\n",
    "    X_train_std=np.nanstd(X_train,axis=0) #Stdev of training data\n",
    "    X_train=(X_train-X_train_mean)/X_train_std #Z-score training data\n",
    "    X_test=(X_test-X_train_mean)/X_train_std #Preprocess testing data in same manner as training data\n",
    "    X_valid=(X_valid-X_train_mean)/X_train_std #Preprocess validation data in same manner as training data\n",
    "\n",
    "    #Z-score \"X_flat\" inputs. \n",
    "    X_flat_train_mean=np.nanmean(X_flat_train,axis=0)\n",
    "    X_flat_train_std=np.nanstd(X_flat_train,axis=0)\n",
    "    X_flat_train=(X_flat_train-X_flat_train_mean)/X_flat_train_std\n",
    "    X_flat_test=(X_flat_test-X_flat_train_mean)/X_flat_train_std\n",
    "    X_flat_valid=(X_flat_valid-X_flat_train_mean)/X_flat_train_std\n",
    "\n",
    "    #Zero-center outputs\n",
    "    y_train_mean=np.nanmean(y_train,axis=0) #Mean of training data outputs\n",
    "    y_train=y_train-y_train_mean #Zero-center training output\n",
    "    y_test=y_test-y_train_mean #Preprocess testing data in same manner as training data\n",
    "    y_valid=y_valid-y_train_mean #Preprocess validation data in same manner as training data\n",
    "    \n",
    "    #Z-score outputs (for SVR)\n",
    "    y_train_std=np.nanstd(y_train,axis=0)\n",
    "    y_zscore_train=y_train/y_train_std\n",
    "    y_zscore_test=y_test/y_train_std\n",
    "    y_zscore_valid=y_valid/y_train_std    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ################# DECODING #################\n",
    "    \n",
    "    #Add actual train/valid/test data to lists (for saving)\n",
    "    y_test_all.append(y_test)\n",
    "    y_train_all.append(y_train)\n",
    "    y_valid_all.append(y_valid)\n",
    "\n",
    "\n",
    "    \n",
    "    ###### WIENER FILTER ######\n",
    "    if run_wf:\n",
    "        #Note - the Wiener Filter has no hyperparameters to fit, unlike all other methods\n",
    "        \n",
    "        #Declare model\n",
    "        model_wf=WienerFilterDecoder()\n",
    "        #Fit model on training data\n",
    "        model_wf.fit(X_flat_train,y_train)\n",
    "        #Get test set predictions\n",
    "        y_test_predicted_wf=model_wf.predict(X_flat_test)   \n",
    "        #Get R2 of test set (mean of x and y values of position/velocity)\n",
    "        mean_r2_wf[i]=np.mean(get_R2(y_test,y_test_predicted_wf))\n",
    "        #Print R2 values on test set\n",
    "        R2s_wf=get_R2(y_test,y_test_predicted_wf)\n",
    "        print('R2s_wf:', R2s_wf)\n",
    "        \n",
    "        #Add predictions of training/validation/testing to lists (for saving)\n",
    "        y_pred_wf_all.append(y_test_predicted_wf)        \n",
    "        y_train_pred_wf_all.append(model_wf.predict(X_flat_train))\n",
    "        y_valid_pred_wf_all.append(model_wf.predict(X_flat_valid))        \n",
    "\n",
    "        \n",
    "    ###### WIENER CASCADE ######\n",
    "    if run_wc:\n",
    "        \n",
    "        ### Get hyperparameters using Bayesian optimization based on validation set R2 values###\n",
    "    \n",
    "        #Define a function that returns the metric we are trying to optimize (R2 value of the validation set)\n",
    "        #as a function of the hyperparameter we are fitting (here, degree)\n",
    "        def wc_evaluate(degree):\n",
    "            model_wc=WienerCascadeDecoder(degree) #Define model\n",
    "            model_wc.fit(X_flat_train,y_train) #Fit model\n",
    "            y_valid_predicted_wc=model_wc.predict(X_flat_valid) #Validation set predictions\n",
    "            return np.mean(get_R2(y_valid,y_valid_predicted_wc)) #R2 value of validation set (mean over x and y position/velocity)\n",
    "        \n",
    "        #Do bayesian optimization\n",
    "        wcBO = BayesianOptimization(wc_evaluate, {'degree': (1, 5.01)}, verbose=0) #Define Bayesian optimization, and set limits of hyperparameters    \n",
    "        wcBO.maximize(init_points=3, n_iter=3) #Set number of initial runs and subsequent tests, and do the optimization\n",
    "        best_params=wcBO.res['max']['max_params'] #Get the hyperparameters that give rise to the best fit\n",
    "        degree=best_params['degree']\n",
    "#         print(\"degree=\", degree)\n",
    "\n",
    "        ### Run model w/ above hyperparameters\n",
    "        \n",
    "        model_wc=WienerCascadeDecoder(degree) #Declare model\n",
    "        model_wc.fit(X_flat_train,y_train) #Fit model on training data\n",
    "        y_test_predicted_wc=model_wc.predict(X_flat_test) #Get test set predictions\n",
    "        mean_r2_wc[i]=np.mean(get_R2(y_test,y_test_predicted_wc)) #Get test set R2 (mean across x and y position/velocity)\n",
    "        #Print R2 values on test set\n",
    "        R2s_wc=get_R2(y_test,y_test_predicted_wc)\n",
    "        print('R2s_wc:', R2s_wc)\n",
    "        #Add predictions of training/validation/testing to lists (for saving)\n",
    "        y_pred_wc_all.append(y_test_predicted_wc)   \n",
    "        y_train_pred_wc_all.append(model_wc.predict(X_flat_train))\n",
    "        y_valid_pred_wc_all.append(model_wc.predict(X_flat_valid))\n",
    "\n",
    " \n",
    "\n",
    "    ###### SVR ######\n",
    "    if run_svr:\n",
    "        \n",
    "        ### Get hyperparameters using Bayesian optimization based on validation set R2 values###\n",
    "        \n",
    "        #Set the maximum number of iterations (to save time) - 2000 for M1 and S1, 4000 for HC which is faster\n",
    "        if dataset=='hc':\n",
    "            max_iter=4000\n",
    "        else:\n",
    "            max_iter=2000\n",
    "        \n",
    "        #Define a function that returns the metric we are trying to optimize (R2 value of the validation set)\n",
    "        #as a function of the hyperparameter we are fitting (here, C)\n",
    "        def svr_evaluate(C):\n",
    "            model_svr=SVRDecoder(C=C, max_iter=max_iter)\n",
    "            model_svr.fit(X_flat_train,y_zscore_train) #Note for SVR that we use z-scored y values\n",
    "            y_valid_predicted_svr=model_svr.predict(X_flat_valid)\n",
    "            return np.mean(get_R2(y_zscore_valid,y_valid_predicted_svr))\n",
    "        \n",
    "        #Do bayesian optimization\n",
    "        svrBO = BayesianOptimization(svr_evaluate, {'C': (.5, 10)}, verbose=0)    \n",
    "        svrBO.maximize(init_points=5, n_iter=5)\n",
    "        best_params=svrBO.res['max']['max_params']\n",
    "        C=best_params['C']\n",
    "#         print(\"C=\", C)\n",
    "\n",
    "        # Run model w/ above hyperparameters\n",
    "    \n",
    "        model_svr=SVRDecoder(C=C, max_iter=max_iter)\n",
    "        model_svr.fit(X_flat_train,y_zscore_train) #Note for SVR that we use z-scored y values\n",
    "        y_test_predicted_svr=model_svr.predict(X_flat_test)\n",
    "        mean_r2_svr[i]=np.mean(get_R2(y_zscore_test,y_test_predicted_svr))    \n",
    "        #Print R2 values on test set\n",
    "        R2s_svr=get_R2(y_zscore_test,y_test_predicted_svr)\n",
    "        print('R2s_svr:', R2s_svr)    \n",
    "        #Add predictions of training/validation/testing to lists (for saving)    \n",
    "        y_pred_svr_all.append(y_test_predicted_svr)\n",
    "        y_train_pred_svr_all.append(model_svr.predict(X_flat_train))\n",
    "        y_valid_pred_svr_all.append(model_svr.predict(X_flat_valid))\n",
    "\n",
    "        \n",
    "        \n",
    "    ##### XGBOOST ######\n",
    "    if run_xgb:\n",
    "               \n",
    "        ### Get hyperparameters using Bayesian optimization based on validation set R2 values###\n",
    "    \n",
    "        #Define a function that returns the metric we are trying to optimize (R2 value of the validation set)\n",
    "        #as a function of the hyperparameter we are fitting (max_depth, num_round, eta)\n",
    "        def xgb_evaluate(max_depth,num_round,eta):\n",
    "            max_depth=int(max_depth) #Put in proper format (Bayesian optimization uses floats, and we just want to test the integer)\n",
    "            num_round=int(num_round) #Put in proper format\n",
    "            eta=float(eta) #Put in proper format\n",
    "            model_xgb=XGBoostDecoder(max_depth=max_depth, num_round=num_round, eta=eta) #Define model\n",
    "            model_xgb.fit(X_flat_train,y_train) #Fit model\n",
    "            y_valid_predicted_xgb=model_xgb.predict(X_flat_valid) #Get validation set predictions\n",
    "            return np.mean(get_R2(y_valid,y_valid_predicted_xgb)) #Return mean validation set R2\n",
    "\n",
    "        #Do bayesian optimization\n",
    "        xgbBO = BayesianOptimization(xgb_evaluate, {'max_depth': (2, 10.01), 'num_round': (100,700), 'eta': (0, 1)}) #Define Bayesian optimization, and set limits of hyperparameters    \n",
    "        #Set number of initial runs and subsequent tests, and do the optimization. Also, we set kappa=10 (greater than the default) so there is more exploration when there are more hyperparameters\n",
    "        xgbBO.maximize(init_points=20, n_iter=20, kappa=10) \n",
    "        best_params=xgbBO.res['max']['max_params'] #Get the hyperparameters that give rise to the best fit\n",
    "        num_round=np.int(best_params['num_round']) #We want the integer value associated with the best \"num_round\" parameter (which is what the xgb_evaluate function does above)\n",
    "        max_depth=np.int(best_params['max_depth']) #We want the integer value associated with the best \"max_depth\" parameter (which is what the xgb_evaluate function does above)\n",
    "        eta=best_params['eta']\n",
    "    \n",
    "        # Run model w/ above hyperparameters\n",
    "        \n",
    "        model_xgb=XGBoostDecoder(max_depth=max_depth, num_round=num_round, eta=eta) #Declare model w/ fit hyperparameters\n",
    "        model_xgb.fit(X_flat_train,y_train) #Fit model\n",
    "        y_test_predicted_xgb=model_xgb.predict(X_flat_test) #Get test set predictions\n",
    "        mean_r2_xgb[i]=np.mean(get_R2(y_test,y_test_predicted_xgb)) #Get test set R2 (mean across x and y position/velocity)   \n",
    "        #Print R2 values on test set\n",
    "        R2s_xgb=get_R2(y_test,y_test_predicted_xgb)\n",
    "        print('R2s:', R2s_xgb)\n",
    "        #Add predictions of training/validation/testing to lists (for saving)        \n",
    "        y_pred_xgb_all.append(y_test_predicted_xgb)                    \n",
    "        y_train_pred_xgb_all.append(model_xgb.predict(X_flat_train))\n",
    "        y_valid_pred_xgb_all.append(model_xgb.predict(X_flat_valid))\n",
    "        \n",
    "        \n",
    "    \n",
    "    ##### Dense (Feedforward) NN ######\n",
    "    if run_dnn:\n",
    "        \n",
    "        ### Get hyperparameters using Bayesian optimization based on validation set R2 values###\n",
    "    \n",
    "        #Define a function that returns the metric we are trying to optimize (R2 value of the validation set)\n",
    "        #as a function of the hyperparameter we are fitting        \n",
    "        def dnn_evaluate(num_units,frac_dropout,n_epochs):\n",
    "            num_units=int(num_units)\n",
    "            frac_dropout=float(frac_dropout)\n",
    "            n_epochs=int(n_epochs)\n",
    "            model_dnn=DenseNNDecoder(units=[num_units,num_units],dropout=frac_dropout,num_epochs=n_epochs)\n",
    "            model_dnn.fit(X_flat_train,y_train)\n",
    "            y_valid_predicted_dnn=model_dnn.predict(X_flat_valid)\n",
    "            return np.mean(get_R2(y_valid,y_valid_predicted_dnn))\n",
    "        \n",
    "        #Do bayesian optimization\n",
    "        dnnBO = BayesianOptimization(dnn_evaluate, {'num_units': (50, 600), 'frac_dropout': (0,.5), 'n_epochs': (2,21)})\n",
    "        dnnBO.maximize(init_points=20, n_iter=20, kappa=10)\n",
    "        best_params=dnnBO.res['max']['max_params']\n",
    "        frac_dropout=float(best_params['frac_dropout'])\n",
    "        n_epochs=np.int(best_params['n_epochs'])\n",
    "        num_units=np.int(best_params['num_units'])\n",
    "\n",
    "        # Run model w/ above hyperparameters\n",
    "        \n",
    "        model_dnn=DenseNNDecoder(units=[num_units,num_units],dropout=frac_dropout,num_epochs=n_epochs)\n",
    "        model_dnn.fit(X_flat_train,y_train)\n",
    "        y_test_predicted_dnn=model_dnn.predict(X_flat_test)\n",
    "        mean_r2_dnn[i]=np.mean(get_R2(y_test,y_test_predicted_dnn))    \n",
    "        #Print R2 values on test set\n",
    "        R2s_dnn=get_R2(y_test,y_test_predicted_dnn)\n",
    "        print('R2s:', R2s_dnn)    \n",
    "        #Add predictions of training/validation/testing to lists (for saving)            \n",
    "        y_pred_dnn_all.append(y_test_predicted_dnn)\n",
    "        y_train_pred_dnn_all.append(model_dnn.predict(X_flat_train))\n",
    "        y_valid_pred_dnn_all.append(model_dnn.predict(X_flat_valid))\n",
    "        \n",
    "        \n",
    "        \n",
    "    ##### SIMPLE RNN ######\n",
    "    if run_rnn:\n",
    "        \n",
    "        ### Get hyperparameters using Bayesian optimization based on validation set R2 values###\n",
    "    \n",
    "        #Define a function that returns the metric we are trying to optimize (R2 value of the validation set)\n",
    "        #as a function of the hyperparameter we are fitting\n",
    "        def rnn_evaluate(num_units,frac_dropout,n_epochs):\n",
    "            num_units=int(num_units)\n",
    "            frac_dropout=float(frac_dropout)\n",
    "            n_epochs=int(n_epochs)\n",
    "            model_rnn=SimpleRNNDecoder(units=num_units,dropout=frac_dropout,num_epochs=n_epochs)\n",
    "            model_rnn.fit(X_train,y_train)\n",
    "            y_valid_predicted_rnn=model_rnn.predict(X_valid)\n",
    "            return np.mean(get_R2(y_valid,y_valid_predicted_rnn))\n",
    "        \n",
    "        #Do bayesian optimization\n",
    "        rnnBO = BayesianOptimization(rnn_evaluate, {'num_units': (50, 600), 'frac_dropout': (0,.5), 'n_epochs': (2,21)})\n",
    "        rnnBO.maximize(init_points=20, n_iter=20, kappa=10)\n",
    "        best_params=rnnBO.res['max']['max_params']\n",
    "        frac_dropout=float(best_params['frac_dropout'])\n",
    "        n_epochs=np.int(best_params['n_epochs'])\n",
    "        num_units=np.int(best_params['num_units'])\n",
    "\n",
    "        # Run model w/ above hyperparameters\n",
    "        \n",
    "        model_rnn=SimpleRNNDecoder(units=num_units,dropout=frac_dropout,num_epochs=n_epochs)\n",
    "        model_rnn.fit(X_train,y_train)\n",
    "        y_test_predicted_rnn=model_rnn.predict(X_test)\n",
    "        mean_r2_rnn[i]=np.mean(get_R2(y_test,y_test_predicted_rnn))    \n",
    "        #Print R2 values on test set\n",
    "        R2s_rnn=get_R2(y_test,y_test_predicted_rnn)\n",
    "        print('R2s:', R2s_rnn)\n",
    "        #Add predictions of training/validation/testing to lists (for saving)           \n",
    "        y_pred_rnn_all.append(y_test_predicted_rnn)\n",
    "        y_train_pred_rnn_all.append(model_rnn.predict(X_train))\n",
    "        y_valid_pred_rnn_all.append(model_rnn.predict(X_valid))  \n",
    "    \n",
    "    ##### GRU ######\n",
    "    if run_gru:\n",
    "        \n",
    "        ### Get hyperparameters using Bayesian optimization based on validation set R2 values###\n",
    "    \n",
    "        #Define a function that returns the metric we are trying to optimize (R2 value of the validation set)\n",
    "        #as a function of the hyperparameter we are fitting        \n",
    "        def gru_evaluate(num_units,frac_dropout,n_epochs):\n",
    "            num_units=int(num_units)\n",
    "            frac_dropout=float(frac_dropout)\n",
    "            n_epochs=int(n_epochs)\n",
    "            model_gru=GRUDecoder(units=num_units,dropout=frac_dropout,num_epochs=n_epochs)\n",
    "            model_gru.fit(X_train,y_train)\n",
    "            y_valid_predicted_gru=model_gru.predict(X_valid)\n",
    "            return np.mean(get_R2(y_valid,y_valid_predicted_gru))\n",
    "        \n",
    "        #Do bayesian optimization\n",
    "        gruBO = BayesianOptimization(gru_evaluate, {'num_units': (50, 600), 'frac_dropout': (0,.5), 'n_epochs': (2,21)})\n",
    "        gruBO.maximize(init_points=20, n_iter=20,kappa=10)\n",
    "        best_params=gruBO.res['max']['max_params']\n",
    "        frac_dropout=float(best_params['frac_dropout'])\n",
    "        n_epochs=np.int(best_params['n_epochs'])\n",
    "        num_units=np.int(best_params['num_units'])\n",
    "\n",
    "        # Run model w/ above hyperparameters\n",
    "        \n",
    "        model_gru=GRUDecoder(units=num_units,dropout=frac_dropout,num_epochs=n_epochs)\n",
    "        model_gru.fit(X_train,y_train)\n",
    "        y_test_predicted_gru=model_gru.predict(X_test)\n",
    "        mean_r2_gru[i]=np.mean(get_R2(y_test,y_test_predicted_gru))    \n",
    "        #Print test set R2 values\n",
    "        R2s_gru=get_R2(y_test,y_test_predicted_gru)\n",
    "        print('R2s:', R2s_gru)\n",
    "        #Add predictions of training/validation/testing to lists (for saving)            \n",
    "        y_pred_gru_all.append(y_test_predicted_gru)\n",
    "        y_train_pred_gru_all.append(model_gru.predict(X_train))\n",
    "        y_valid_pred_gru_all.append(model_gru.predict(X_valid))  \n",
    "    \n",
    "    \n",
    "    ##### LSTM ######\n",
    "    if run_lstm:\n",
    "        \n",
    "        ### Get hyperparameters using Bayesian optimization based on validation set R2 values###\n",
    "    \n",
    "        #Define a function that returns the metric we are trying to optimize (R2 value of the validation set)\n",
    "        #as a function of the hyperparameter we are fitting        \n",
    "        def lstm_evaluate(num_units,frac_dropout,n_epochs):\n",
    "            num_units=int(num_units)\n",
    "            frac_dropout=float(frac_dropout)\n",
    "            n_epochs=int(n_epochs)\n",
    "            model_lstm=LSTMDecoder(units=num_units,dropout=frac_dropout,num_epochs=n_epochs)\n",
    "            model_lstm.fit(X_train,y_train)\n",
    "            y_valid_predicted_lstm=model_lstm.predict(X_valid)\n",
    "            return np.mean(get_R2(y_valid,y_valid_predicted_lstm))\n",
    "        \n",
    "        #Do bayesian optimization\n",
    "        lstmBO = BayesianOptimization(lstm_evaluate, {'num_units': (50, 600), 'frac_dropout': (0,.5), 'n_epochs': (2,21)})\n",
    "        lstmBO.maximize(init_points=20, n_iter=20, kappa=10)\n",
    "        best_params=lstmBO.res['max']['max_params']\n",
    "        frac_dropout=float(best_params['frac_dropout'])\n",
    "        n_epochs=np.int(best_params['n_epochs'])\n",
    "        num_units=np.int(best_params['num_units'])\n",
    "\n",
    "        # Run model w/ above hyperparameters\n",
    "        \n",
    "        model_lstm=LSTMDecoder(units=num_units,dropout=frac_dropout,num_epochs=n_epochs)\n",
    "        model_lstm.fit(X_train,y_train)\n",
    "        y_test_predicted_lstm=model_lstm.predict(X_test)\n",
    "        mean_r2_lstm[i]=np.mean(get_R2(y_test,y_test_predicted_lstm))    \n",
    "        #Print test set R2\n",
    "        R2s_lstm=get_R2(y_test,y_test_predicted_lstm)\n",
    "        print('R2s:', R2s_lstm)   \n",
    "        #Add predictions of training/validation/testing to lists (for saving)        \n",
    "        y_pred_lstm_all.append(y_test_predicted_lstm)\n",
    "        y_train_pred_lstm_all.append(model_lstm.predict(X_train))\n",
    "        y_valid_pred_lstm_all.append(model_lstm.predict(X_valid))    \n",
    "       \n",
    "    print (\"\\n\") #Line break after each fold   \n",
    "    time_elapsed=time.time()-t1 #How much time has passed\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###### SAVE RESULTS #####\n",
    "    #Note that I save them after every cross-validation fold rather than at the end in case the code/computer crashes for some reason while running\n",
    "    \n",
    "    #Only save results for the decoder we chose to run\n",
    "    if run_wf:\n",
    "        with open(save_folder+dataset+'_results_wf2.pickle','wb') as f:\n",
    "            pickle.dump([mean_r2_wf,y_pred_wf_all,y_train_pred_wf_all,y_valid_pred_wf_all],f)\n",
    "\n",
    "    if run_wc:\n",
    "        with open(save_folder+dataset+'_results_wc2.pickle','wb') as f:\n",
    "            pickle.dump([mean_r2_wc,y_pred_wc_all,y_train_pred_wc_all,y_valid_pred_wc_all],f)\n",
    "\n",
    "    if run_xgb:\n",
    "        with open(save_folder+dataset+'_results_xgb2.pickle','wb') as f:\n",
    "            pickle.dump([mean_r2_xgb,y_pred_xgb_all,y_train_pred_xgb_all,y_valid_pred_xgb_all,time_elapsed],f)\n",
    "\n",
    "    if run_dnn:\n",
    "        with open(save_folder+dataset+'_results_dnn2.pickle','wb') as f:\n",
    "            pickle.dump([mean_r2_dnn,y_pred_dnn_all,y_train_pred_dnn_all,y_valid_pred_dnn_all,time_elapsed],f)\n",
    "\n",
    "    if run_rnn:\n",
    "        with open(save_folder+dataset+'_results_rnn2.pickle','wb') as f:\n",
    "            pickle.dump([mean_r2_rnn,y_pred_rnn_all,y_train_pred_rnn_all,y_valid_pred_rnn_all,time_elapsed],f)\n",
    "\n",
    "    if run_gru:\n",
    "        with open(save_folder+dataset+'_results_gru2.pickle','wb') as f:\n",
    "            pickle.dump([mean_r2_gru,y_pred_gru_all,y_train_pred_gru_all,y_valid_pred_gru_all,time_elapsed],f)\n",
    "\n",
    "    if run_lstm:\n",
    "        with open(save_folder+dataset+'_results_lstm2.pickle','wb') as f:\n",
    "            pickle.dump([mean_r2_lstm,y_pred_lstm_all,y_train_pred_lstm_all,y_valid_pred_lstm_all,time_elapsed],f)\n",
    "\n",
    "    if run_svr:\n",
    "        with open(save_folder+dataset+'_results_svr2.pickle','wb') as f:\n",
    "            pickle.dump([mean_r2_svr,y_pred_svr_all,y_train_pred_svr_all,y_valid_pred_svr_all,time_elapsed],f)\n",
    "            \n",
    "            \n",
    "#Save ground truth results\n",
    "with open(save_folder+dataset+'_ground_truth.pickle','wb') as f:\n",
    "    pickle.dump([y_test_all,y_train_all,y_valid_all],f)\n",
    "    \n",
    "print(\"time_elapsed:\",time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.75235363,  0.75042183,  0.75190676,  0.78076188,  0.73743047,\n",
       "        0.74347408,  0.72087311,  0.75212028,  0.72939737,  0.74985633])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_r2_wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74685957390368962"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean_r2_wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd456ca4250>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd456ca4610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test_all[1][0:1000,0])\n",
    "plt.plot(y_pred_wf_all[1][0:1000,0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
