{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages\n",
    "\n",
    "Below, we import both standard packages, and functions from the accompanying .py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release.  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 3: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "#Import standard packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "#Import metrics\n",
    "from metrics import get_R2\n",
    "from metrics import get_rho\n",
    "\n",
    "#Import decoder functions\n",
    "from decoders import KalmanFilterDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "The data that we load is in the format described below. We have another example script, \"neural_preprocessing.py\" that may be helpful towards putting the data in this format.\n",
    "\n",
    "Neural data should be a matrix of size \"number of time bins\" x \"number of neurons\", where each entry is the firing rate of a given neuron in a given time bin\n",
    "\n",
    "The output you are decoding should be a matrix of size \"number of time bins\" x \"number of features you are decoding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# folder='/Users/jig289/Dropbox/MATLAB/Projects/In_Progress/BMI/Processed_Data/'\n",
    "# folder='/Users/jig289/Dropbox/Grad_School/Research/Projects/In_Progress/Decoding/DataFiles/'\n",
    "folder='/home/jglaser2/Data/DecData/'\n",
    "\n",
    "with open(folder+'m1_test_data.pickle','rb') as f:\n",
    "    neural_data,vels_binned,pos_binned,acc_binned=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A. User Inputs\n",
    "The user can define what time period to use spikes from (with respect to the output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lag=-2 #What time bin of spikes should be used relative to the output\n",
    "#(lag=-1 means use the spikes 1 bin before the output)\n",
    "\n",
    "#-2 for m1, 0 for s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B. Format Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The covariate is simply the matrix of firing rates for all neurons over time\n",
    "X_kf=neural_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For the Kalman filter, we use the position, velocity, and acceleration as outputs\n",
    "#Ultimately, we are only concerned with the goodness of fit of velocity (for this dataset)\n",
    "#But using them all as covariates helps performance\n",
    "\n",
    "#We will now determine position\n",
    "pos_binned=np.zeros(vels_binned.shape) #Initialize \n",
    "pos_binned[0,:]=0 #Assume starting position is at [0,0]\n",
    "#Loop through time bins and determine positions based on the velocities\n",
    "for i in range(pos_binned.shape[0]-1): \n",
    "    pos_binned[i+1,0]=pos_binned[i,0]+vels_binned[i,0]*.05 #Note that .05 is the length of the time bin\n",
    "    pos_binned[i+1,1]=pos_binned[i,1]+vels_binned[i,1]*.05\n",
    "\n",
    "#We will now determine acceleration    \n",
    "temp=np.diff(vels_binned,axis=0) #The acceleration is the difference in velocities across time bins \n",
    "acc_binned=np.concatenate((temp,temp[-1:,:]),axis=0) #Assume acceleration at last time point is same as 2nd to last\n",
    "\n",
    "#The final output covariates include position, velocity, and acceleration\n",
    "y_kf=np.concatenate((pos_binned,vels_binned,acc_binned),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3C. Process Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization and zero-centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Z-scoring function that works with Nans:\n",
    "def zscore_nan(X,axis):\n",
    "    X_zscore=(X - np.nanmean(X,axis=axis)) / np.nanstd(X,axis=axis)\n",
    "    return X_zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Normalize inputs\n",
    "X_kf=zscore_nan(X_kf,axis=0)\n",
    "\n",
    "#Zero-center outputs\n",
    "y_kf_mean=np.mean(y_kf,axis=0)\n",
    "y_kf=y_kf-y_kf_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take lag into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_examples=X_kf.shape[0]\n",
    "\n",
    "#Re-align data to take lag into account\n",
    "if lag<0:\n",
    "    y_kf=y_kf[-lag:,:]\n",
    "    X_kf=X_kf[0:num_examples+lag,:]\n",
    "if lag>0:\n",
    "    y_kf=y_kf[0:num_examples-lag,:]\n",
    "    X_kf=X_kf[lag:num_examples,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D. Split into training/testing/validation sets\n",
    "Note that parameters should be setting using a separate validation set. \n",
    "Then, the goodness of fit should be be tested on a testing set (separate from the training and validation sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set what part of data should be part of the training/testing/validation sets\n",
    "training_range=[0, 0.5]\n",
    "testing_range=[0.5, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data: For KF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Number of examples after taking into account bins removed for lag alignment\n",
    "num_examples_kf=X_kf.shape[0]\n",
    "        \n",
    "#Note that each range has a buffer of 1 bin at the beginning and end\n",
    "#This makes it so that the different sets don't include overlapping data\n",
    "training_set=np.arange(np.int(np.round(training_range[0]*num_examples_kf))+1,np.int(np.round(training_range[1]*num_examples_kf))-1)\n",
    "testing_set=np.arange(np.int(np.round(testing_range[0]*num_examples_kf))+1,np.int(np.round(testing_range[1]*num_examples_kf))-1)\n",
    "\n",
    "#Get training data\n",
    "X_kf_train=X_kf[training_set,:]\n",
    "y_kf_train=y_kf[training_set,:]\n",
    "\n",
    "#Get testing data\n",
    "X_kf_test=X_kf[testing_set,:]\n",
    "y_kf_test=y_kf[testing_set,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Decoders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Declare model\n",
    "model_kf=KalmanFilterDecoder()\n",
    "\n",
    "#Fit model\n",
    "model_kf.fit(X_kf_train,y_kf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Get Fits on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_tests=10\n",
    "num_test_examples=y_kf_test.shape[0]\n",
    "num_examples_per_test=np.round(np.divide(num_test_examples,num_tests))\n",
    "\n",
    "#Initialize\n",
    "mean_R2_kf=np.empty(num_tests)\n",
    "\n",
    "for i in range(num_tests):\n",
    "\n",
    "    idx=np.arange(num_examples_per_test*i,num_examples_per_test*(i+1))\n",
    "    X_kf_test_temp=X_kf_test[idx,:]\n",
    "    y_kf_test_temp=y_kf_test[idx,:]\n",
    "\n",
    "    #Kalman Filter\n",
    "    y_predicted_kf=model_kf.predict(X_kf_test_temp,y_kf_test_temp)\n",
    "    mean_R2_kf[i]=np.mean(get_R2(y_kf_test_temp,y_predicted_kf)[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4e8b5d3ede1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnum_bs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnum_test_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnum_examples_per_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_test_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "num_splits=10\n",
    "num_bs=200\n",
    "num_test_examples=y_test.shape[0]\n",
    "num_examples_per_split=np.round(np.divide(num_test_examples,num_splits))\n",
    "\n",
    "#Initialize\n",
    "mean_R2_kf=np.empty(num_bs)\n",
    "\n",
    "y_preds_kf=np.empty([num_splits,num_examples_per_split,y_test.shape[1]])\n",
    "\n",
    "for i in range(num_splits):\n",
    "    idx=np.arange(num_examples_per_split*i,num_examples_per_split*(i+1))\n",
    "    X_test_temp=X_test[idx,:,:]\n",
    "    X_flat_test_temp=X_flat_test[idx,:]\n",
    "    \n",
    "    #Kalman Filter\n",
    "    y_preds_kf[i,:,:]=model_kf.predict(X_kf_test_temp,y_kf_test_temp)\n",
    "\n",
    "    \n",
    "y_test_bs=np.empty([num_splits,num_examples_per_split,y_test.shape[1]])\n",
    "for i in range(num_splits):\n",
    "    idx=np.arange(num_examples_per_split*i,num_examples_per_split*(i+1))\n",
    "    y_test_bs[i,:,:]=y_test[idx,:]    \n",
    "    \n",
    "for i in range(num_bs): \n",
    "    \n",
    "    random_idxs=np.floor(num_splits*np.random.rand(10)).astype(int)\n",
    "    y_test_temp=np.reshape(y_test_bs[random_idxs,:,:],[y_test_bs.shape[0]*y_test_bs.shape[1],y_test_bs.shape[2]])    \n",
    "    y_predicted_kf=np.reshape(y_preds_kf[random_idxs,:,:],[y_test_bs.shape[0]*y_test_bs.shape[1],y_test_bs.shape[2]])    \n",
    "    \n",
    "    mean_R2_kf[i]=np.mean(get_R2(y_kf_test_temp,y_predicted_kf)[2:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_R2_kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(mean_R2_kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_folder='/home/jglaser2/Data/Decoding_Results/'\n",
    "with open(save_folder+'m1_results_kf.pickle','wb') as f:\n",
    "    pickle.dump([mean_R2_kf],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
