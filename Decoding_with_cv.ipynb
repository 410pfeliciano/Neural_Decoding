{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using Theano backend.\n",
      "Using gpu device 3: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5103)\n",
      "/opt/anaconda/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "#Import function to get the covariate matrix that includes spike history from previous bins\n",
    "from preprocessing_funcs import get_spikes_with_history\n",
    "\n",
    "#Import decoder functions\n",
    "import Decoder_funcs\n",
    "from Decoder_funcs import get_vaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural data should be a matrix of size \"number of time bins\" x \"number of neurons\", where each entry is the firing rate of a given neuron in a given time bin**\n",
    "\n",
    "**The output you are decoding should be a matrix of size \"number of time bins\" x \"number of features you are decoding\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# folder='/Users/jig289/Dropbox/MATLAB/Projects/In_Progress/BMI/Processed_Data/'\n",
    "folder='/home/jglaser2/Data/DecData/'\n",
    "\n",
    "with open(folder+'test_data.pickle','rb') as f:\n",
    "    neural_data,vels_binned=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Covariates ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins_current=1 #Whether to use concurrent time bin of neural data\n",
    "bins_before=13 #How many bins of neural data prior to the output are used for decoding\n",
    "bins_after=0 #How many bins of neural data after (and including) the output are used for decoding\n",
    "bins_surrounding=bins_before+bins_before+bins_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to get the covariate matrix that includes spike history from previous bins\n",
    "X=get_spikes_with_history(neural_data,bins_before,bins_after,bins_current)\n",
    "\n",
    "#Put in \"flat\" format for XGB and linear\n",
    "X_flat=X.reshape(X.shape[0],(X.shape[1]*X.shape[2]))\n",
    "\n",
    "#Set decoding output\n",
    "y=vels_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# zscore = lambda x: (x - scipy.stats.nanmean(x)) / scipy.stats.nanstd(x)\n",
    "def zscore_nan(X,axis):\n",
    "    X_zscore=(X - np.nanmean(X,axis=axis)) / np.nanstd(X,axis=axis)\n",
    "    return X_zscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Normalize\n",
    "\n",
    "X=zscore_nan(X,axis=0)\n",
    "X_flat=zscore_nan(X_flat,axis=0)\n",
    "\n",
    "#Zero-center outputs\n",
    "y_mean=np.mean(y,axis=0)\n",
    "y=y-y_mean\n",
    "# y=stats.zscore(y,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training/testing/validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#What part of the data you're using (remove the validation set that we fit parameters on)\n",
    "use_range=[0, 0.85]\n",
    "num_examples_orig=X.shape[0]\n",
    "#Below starts at \"bins_before\" and ends with a boundary of \"bins_after\"\n",
    "use_set=np.arange(np.int(np.round(use_range[0]*num_examples_orig)+bins_before),np.int(np.round(use_range[1]*num_examples_orig)-bins_after))\n",
    "X=X[use_set,:,:]\n",
    "X_flat=X_flat[use_set,:]\n",
    "y=y[use_set,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_cv=10\n",
    "cv_frac=num_cv**-1\n",
    "num_examples=X.shape[0]\n",
    "# testing_sets=[] #List of all the testing sets\n",
    "# training_sets=[] #List of all the training sets\n",
    "\n",
    "mean_vafs_lin=np.empty(num_cv)\n",
    "mean_vafs_wc=np.empty(num_cv)\n",
    "mean_vafs_xgb=np.empty(num_cv)\n",
    "mean_vafs_dnn=np.empty(num_cv)\n",
    "mean_vafs_rnn=np.empty(num_cv)\n",
    "mean_vafs_gru=np.empty(num_cv)\n",
    "mean_vafs_lstm=np.empty(num_cv)\n",
    "\n",
    "for i in range(1):#(num_cv):\n",
    "    testing_range=[i*cv_frac,(i+1)*cv_frac]\n",
    "    testing_set=np.arange(np.int(np.round(testing_range[0]*num_examples)),np.int(np.round(testing_range[1]*num_examples)))\n",
    "    training_set=np.arange(num_examples) #Initialize training set as all examples\n",
    "    training_set=np.delete(training_set,testing_set) #Remove testing set from all examples to create training set\n",
    "    #Now make sure there's no overlap between the training/testing sets by removing border entries from test set:\n",
    "    rmv_before=np.arange(0,bins_before)\n",
    "    testing_set=np.delete(testing_set,rmv_before)\n",
    "    rmv_after=np.arange(testing_set.shape[0]-bins_after,testing_set.shape[0])\n",
    "    testing_set=np.delete(testing_set,rmv_after)\n",
    "    \n",
    "    ###Split Data###\n",
    "    X_train=X[training_set,:,:]\n",
    "    X_flat_train=X_flat[training_set,:]\n",
    "    y_train=y[training_set,:]\n",
    "\n",
    "    X_test=X[testing_set,:,:]\n",
    "    X_flat_test=X_flat[testing_set,:]\n",
    "    y_test=y[testing_set,:]\n",
    "    \n",
    "    \n",
    "    ##### DECODERS ########\n",
    "    \n",
    "    ###WIENER FILTER###\n",
    "    model_regr=Decoder_funcs.lin_reg_model(X_flat_train,y_train)\n",
    "    y_test_pred_lin=model_regr.predict(X_flat_test)\n",
    "    vafs_lin=get_vaf(y_test,y_test_pred_lin)\n",
    "    mean_vafs_lin[i]=np.mean(vafs_lin)\n",
    " \n",
    "    ###WIENER CASCADE###\n",
    "    models_wc=Decoder_funcs.wiener_casc_model(X_flat_train,y_train,deg=3)\n",
    "    y_test_pred_wc=Decoder_funcs.wiener_casc_predict(models_wc,X_flat_test)\n",
    "    vafs_wc=get_vaf(y_test,y_test_pred_wc)\n",
    "    mean_vafs_wc[i]=np.mean(vafs_wc)\n",
    "\n",
    "    ###XGBOOST###    \n",
    "    model_xgb=Decoder_funcs.xgb_model(X_flat_train,y_train,max_depth=3,num_round=200) #Fit model\n",
    "    y_test_pred_xgb=Decoder_funcs.xgb_predict(model_xgb,X_flat_test) #Get predictions\n",
    "    vafs_xgb=get_vaf(y_test,y_test_pred_xgb)\n",
    "    mean_vafs_xgb[i]=np.mean(vafs_xgb)    \n",
    "     \n",
    "    ###DENSE NEURAL NETWORK###    \n",
    "    model_dnn=Decoder_funcs.dnn_model(X_flat_train,y_train,num_layers=2,units=400,dropout=0,num_epochs=10)\n",
    "    y_test_pred_dnn=model_dnn.predict(X_test)\n",
    "    vafs_dnn=get_vaf(y_test,y_test_pred_dnn)\n",
    "    mean_vafs_dnn[i]=np.mean(vafs_dnn)    \n",
    "    \n",
    "    ###SIMPLE RNN###\n",
    "    model_rnn=Decoder_funcs.SimpleRNN_model(X_train,y_train,units=400,dropout=0,num_epochs=10)\n",
    "    y_test_pred_rnn=model_rnn.predict(X_test)\n",
    "    vafs_rnn=get_vaf(y_test,y_test_pred_rnn)\n",
    "    mean_vafs_rnn[i]=np.mean(vafs_rnn)\n",
    "\n",
    "    ###GRU###\n",
    "    model_gru=Decoder_funcs.GRU_model(X_train,y_train,units=400,dropout=0,num_epochs=10)\n",
    "    y_test_pred_gru=model_gru.predict(X_test)\n",
    "    vafs_gru=get_vaf(y_test,y_test_pred_gru)\n",
    "    mean_vafs_gru[i]=np.mean(vafs_gru)\n",
    "    \n",
    "    ###LSTM###\n",
    "    model_lstm=Decoder_funcs.LSTM_model(X_train,y_train,units=400,dropout=0,num_epochs=10)\n",
    "    y_test_pred_lstm=model_lstm.predict(X_test)\n",
    "    vafs_lstm=get_vaf(y_test,y_test_pred_lstm)\n",
    "    mean_vafs_lstm[i]=np.mean(vafs_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78245607358\n",
      "0.00974913041087\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(mean_vafs_lin))\n",
    "print(np.std(mean_vafs_lin)/np.sqrt(num_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8053751086088532"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vafs_lin[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81200129,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vafs_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.44479912e-001,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         6.93977503e-310])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vafs_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.94592305e-001,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
       "         6.93977503e-310])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vafs_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
