{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using Theano backend.\n",
      "Using gpu device 3: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5103)\n",
      "/opt/anaconda/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "from scipy import stats\n",
    "import pickle\n",
    "# from numpy.linalg import inv as inv\n",
    "\n",
    "#Import function to get the covariate matrix that includes spike history from previous bins\n",
    "from preprocessing_funcs import get_spikes_with_history\n",
    "\n",
    "#Import decoder functions\n",
    "import Decoder_funcs\n",
    "from Decoder_funcs import get_vaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural data should be a matrix of size \"number of time bins\" x \"number of neurons\", where each entry is the firing rate of a given neuron in a given time bin**\n",
    "\n",
    "**The output you are decoding should be a matrix of size \"number of time bins\" x \"number of features you are decoding\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# folder='/Users/jig289/Dropbox/MATLAB/Projects/In_Progress/BMI/Processed_Data/'\n",
    "folder='/home/jglaser2/Data/DecData/'\n",
    "\n",
    "with open(folder+'test_data.pickle','rb') as f:\n",
    "    neural_data,vels_binned=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Covariates ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Options: Define what time period to use spikes from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lag=-2 #What time bin of spikes should be used relative to the output\n",
    "#(lag=-1 means use the spikes 1 bin before the output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Input Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Format for Kalman filter\n",
    "X_kf=neural_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Output Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set decoding output for the KF\n",
    "pos=np.zeros(vels_binned.shape)\n",
    "pos[0,:]=0\n",
    "for i in range(pos.shape[0]-1):\n",
    "    pos[i+1,0]=pos[i,0]+vels_binned[i,0]*.05\n",
    "    pos[i+1,1]=pos[i,1]+vels_binned[i,1]*.05\n",
    "    \n",
    "temp=np.diff(vels_binned,axis=0)\n",
    "acc=np.concatenate((temp,temp[-1:,:]),axis=0)\n",
    "\n",
    "y_kf=np.concatenate((pos,vels_binned,acc),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def zscore_nan(X,axis):\n",
    "    X_zscore=(X - np.nanmean(X,axis=axis)) / np.nanstd(X,axis=axis)\n",
    "    return X_zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Normalize inputs\n",
    "X_kf=zscore_nan(X_kf,axis=0)\n",
    "\n",
    "#Zero-center outputs\n",
    "y_kf_mean=np.mean(y_kf,axis=0)\n",
    "y_kf=y_kf-y_kf_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#More Kalman filter preprocessing\n",
    "num_examples=X_kf.shape[0]\n",
    "\n",
    "#Re-align data to take lag into account\n",
    "if lag<0:\n",
    "    y_kf=y_kf[-lag:,:]\n",
    "    X_kf=X_kf[0:num_examples+lag,:]\n",
    "if lag>0:\n",
    "    y_kf=y_kf[0:num_examples-lag,:]\n",
    "    X_kf=X_kf[lag:num_examples,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training/testing/validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#What part of the data you're using (remove the validation set that we fit parameters on)\n",
    "use_range=[0, 0.85]\n",
    "num_examples_orig=X_kf.shape[0]\n",
    "#Below starts at \"bins_before\" and ends with a boundary of \"bins_after\"\n",
    "use_set=np.arange(np.int(np.round(use_range[0]*num_examples_orig)),np.int(np.round(use_range[1]*num_examples_orig)))\n",
    "X_kf=X_kf[use_set,:]\n",
    "y_kf=y_kf[use_set,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data: For KF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "#Note that each range has a buffer of 1 bin at the beginning and end\n",
    "#This makes it so that the different sets don't include overlapping data\n",
    "training_set=np.arange(np.int(np.round(training_range[0]*num_examples_kf))+1,np.int(np.round(training_range[1]*num_examples_kf))-1)\n",
    "testing_set=np.arange(np.int(np.round(testing_range[0]*num_examples_kf))+1,np.int(np.round(testing_range[1]*num_examples_kf))-1)\n",
    "valid_set=np.arange(np.int(np.round(valid_range[0]*num_examples_kf))+1,np.int(np.round(valid_range[1]*num_examples_kf))-1)\n",
    "\n",
    "#Get training data\n",
    "X_kf_train=X_kf[training_set,:]\n",
    "y_kf_train=y_kf[training_set,:]\n",
    "\n",
    "#Get testing data\n",
    "X_kf_test=X_kf[testing_set,:]\n",
    "y_kf_test=y_kf[testing_set,:]\n",
    "\n",
    "#Get validation data\n",
    "X_kf_valid=X_kf[valid_set,:]\n",
    "y_kf_valid=y_kf[valid_set,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_cv=10\n",
    "cv_frac=num_cv**-1\n",
    "\n",
    "#Number of examples after taking into account bins removed for lag alignment\n",
    "num_examples=X_kf.shape[0]\n",
    "\n",
    "mean_vafs_kf=np.empty(num_cv)\n",
    "\n",
    "for i in range(2):#(num_cv):\n",
    "    testing_range=[i*cv_frac,(i+1)*cv_frac]\n",
    "    testing_set=np.arange(np.int(np.round(testing_range[0]*num_examples)),np.int(np.round(testing_range[1]*num_examples)))\n",
    "    training_set=np.arange(num_examples) #Initialize training set as all examples\n",
    "    training_set=np.delete(training_set,testing_set) #Remove testing set from all examples to create training set\n",
    "    #Now make sure there's no overlap between the training/testing sets by removing border entries from test set:\n",
    "    rmv_before=np.arange(0,1)\n",
    "    testing_set=np.delete(testing_set,rmv_before)\n",
    "    rmv_after=np.arange(testing_set.shape[0]-1,testing_set.shape[0])\n",
    "    testing_set=np.delete(testing_set,rmv_after)\n",
    "    \n",
    "    ###Split Data###\n",
    "    X_kf_train=X_kf[training_set,:]\n",
    "    y_kf_train=y_kf[training_set,:]\n",
    "\n",
    "    X_kf_test=X_kf[testing_set,:]\n",
    "    y_kf_test=y_kf[testing_set,:]\n",
    "    \n",
    "    \n",
    "    ##### DECODERS ########\n",
    "    \n",
    "    ###WIENER FILTER###\n",
    "    model_kf=Decoder_funcs.kf_model(X_kf_train,y_kf_train)\n",
    "    y_test_pred_kf=Decoder_funcs.kf_predict(model_kf,X_kf_test,y_kf_test)\n",
    "    vafs_kf=get_vaf(y_kf_test,y_test_pred_kf)\n",
    "    mean_vafs_kf[i]=np.mean(vafs_kf[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77626748,  0.80713614,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vafs_kf"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
